idt <- ind[1:25]
cat(idt)
cat("\n")
dtrain <- datos[-idt,]
dtest <- datos[idt,]
clasificadores[[i+1]] = rpart(recid ~., data = dtrain)
}
set.seed(Sys.Date());
# Elegimos una instancia al azar
instancia <- datos[sample(nrow(datos), 1), ]
# Predecimos con cada clasificador
predicciones = vector();
for(i in 1:pasos-1){
predicciones [[i]] <- predict(clasificadores[[i]],instancia,type="prob")
}
predict(clasificadores[[i]],instancia,type="prob")
for(i in 0:5){
set.seed(15*i);
ind<- sample(500,500)
idt <- ind[1:25]
cat(idt)
cat("\n")
dtrain <- datos[-idt,]
dtest <- datos[idt,]
clasificadores[[i+1]] = rpart(recid ~., data = dtrain, control = rpart.control(minsplit = 10))
}
set.seed(Sys.Date());
# Elegimos una instancia al azar
instancia <- datos[sample(nrow(datos), 1), ]
# Predecimos con cada clasificador
predicciones = vector();
for(i in 1:pasos-1){
predicciones [[i]] <- predict(clasificadores[[i]],instancia,type="prob")
}
predict(clasificadores[[i]],instancia,type="prob")
View(clasificadores)
View(instancia)
# Predecimos con cada clasificador
predict_i = function(i,Data){
predict(FIT[[i]],newdata=,Data,type="prob")[,2]
}
predicciones = Vectorize(predict_i,instancia)(1:n)
predicciones = Vectorize(predict_i)(1:n,instancia)
# Predecimos con cada clasificador
predict_i = function(i){
predict(clasificadores[[i]],newdata=instancia,type="prob")[,2]
}
predicciones = Vectorize(predict_i)(1:n)
predicciones = Vectorize(predict_i)(1:pasos)
# Mostramos las predicciones
numClases = ncol(predicciones[[i]])
probs <- array(0,dim=c(0,numClases))
# Mostramos las predicciones
numClases = ncol(predicciones)
# Mostramos las predicciones
numClases =length(predicciones)
probs <- array(0,dim=c(0,numClases))
for(j in 1:numClases){
probs[j] = 0
}
predicciones[i]
predicciones[1]
for(i in 1:pasos){
for(j in 1:numClases){
probs[j] = probs[j] + predicciones[i]
}
}
# Devolvemos el Ã???ndice de la clase
which.max(predicciones)
cat(paste(predicciones,collapse = " "))
cat(\n)
cat("\n")
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5.R')
predicciones = predict_i(1:pasos)
predicciones = predict_i(1)
predicciones = predict_i(2)
# Predecimos con cada clasificador
predict_i = function(i){
predict(clasificadores[[i]],newdata=instancia,type="prob")
}
predicciones = predict_i(2)
View(predicciones)
predicciones = predict_i(1)
predicciones = Vectorize(predict_i)(1:pasos)
View(predicciones)
predict(clasificadores[[1]],instancia,type="prob"))
predict(clasificadores[[1]],instancia,type="prob")
predict(clasificadores[[1]],instancia,type="prob")[1][1]
predict(clasificadores[[1]],instancia,type="prob")[1][2]
predicciones[1][2]
predicciones[1][1]
predicciones[1][0]
predicciones[1][4]
predicciones[1][1]
predicciones[1][2]
predicciones[1][3]
predicciones[6][1]
predicciones[[1]][1]
predicciones[[2]][1]
predicciones[[2]][2]
predicciones
predicciones <- list()
for(i in 1:pasos){
predicciones[[i]] = (predict_i)(i)
}
View(predicciones)
ncol(predicciones[[i]])
# Mostramos las predicciones
numClases = ncol(predicciones[[i]])
probs <- array(0,dim=c(0,numClases))
for(j in 1:numClases){
probs[j] = 0
}
for(i in 1:pasos){
for(j in 1:numClases){
probs[j] = probs[j] + predicciones[[i]][j]
}
}
# Devolvemos el Ã???ndice de la clase
cat(which.max(probs))
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5(1).R')
View(predicciones)
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5(1).R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5(1).R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5(1).R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5(1).R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5(1).R')
predicciones[]
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5.R')
cat(predicciones[])
show(predicciones[])
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Problema 5.R')
recidiva
setwd("D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Examen")
datos<- read.csv("detect-malicious-URL.csv")
View(datos)
datos$X<-null
datos$X<-Null
datos$X<-NULL
rm(list = ls())
library(randomForest)
Data<- read.csv("detect-malicious-URL.csv")
Data$X<-NULL
size <- length(Data[[1]])
ind <- sample(size, size)
accuracyRF<-vector()
k <- 10
#Perform k fold cross validation
for(i in 1:k){
ii <- floor(size/k)*(i-1)+1
is <- floor(size/k)*i
idt <- ind[ii : is]
dtrain <- DataTrain[-idt,]
dtest <- DataTrain[idt,]
RandForest<-RandForest(label.~,)
predRF <- predict(RandForest, dtest)
predRF <- round(predRF)
confusionMatrixRF<-table(predRF, dtest$label)
accuracyRF[i]<-sum(diag(confusionMatrixRF))/sum(confusionMatrixRF)
}
#Perform k fold cross validation
for(i in 1:k){
ii <- floor(size/k)*(i-1)+1
is <- floor(size/k)*i
idt <- ind[ii : is]
dtrain <- DataTrain[-idt,]
dtest <- DataTrain[idt,]
RandForest<-RandForest(label.~,dtrain, ntree=100,importance=T)
predRF <- predict(RandForest, dtest)
predRF <- round(predRF)
confusionMatrixRF<-table(predRF, dtest$label)
accuracyRF[i]<-sum(diag(confusionMatrixRF))/sum(confusionMatrixRF)
}
i<-1L
ii <- floor(size/k)*(i-1)+1
is <- floor(size/k)*i
idt <- ind[ii : is]
dtrain <- DataTrain[-idt,]
dtrain <- Data[-idt,]
dtest <- Data[idt,]
RandForest<-RandForest(label.~,dtrain, ntree=100,importance=T)
RandForest<-RandForest(label~.,dtrain, ntree=100,importance=T)
RandForest<-randomForest(label~.,dtrain, ntree=100,importance=T)
predRF <- predict(RandForest, dtest)
predRF <- round(predRF)
predRF
confusionMatrixRF<-table(predRF, dtest$label)
accuracyRF[i]<-sum(diag(confusionMatrixRF))/sum(confusionMatrixRF)
#Perform k fold cross validation
for(i in 1:k){
ii <- floor(size/k)*(i-1)+1
is <- floor(size/k)*i
idt <- ind[ii : is]
dtrain <- Data[-idt,]
dtest <- Data[idt,]
RandForest<-randomForest(label~.,dtrain, ntree=100,importance=T)
predRF <- predict(RandForest, dtest)
confusionMatrixRF<-table(predRF, dtest$label)
accuracyRF[i]<-sum(diag(confusionMatrixRF))/sum(confusionMatrixRF)
}
cat("Media del acurracy: ",mean (accuracyRF),"\n")
miss_index<-vector();
miss_index[1]<-c(2,4,7,9,10)
miss_index[2]<-c(2,5,6,9,10)
miss_index<-list();
miss_index[[1]]<-c(2,4,7,9,10)
miss_index[[2]]<-c(2,5,6,9,10)
miss_index[[1]]
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Examen/Ejercicio2.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Examen/Ejercicio2.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Examen/Ejercicio2.R')
i<-1L
y_h<-rep(1,n)
index <- miss_index[[i]]
cat(sprintf("d%d:\t",i))
cat(sprintf("%.4f\t",d))
y_h[index]=-1
error <- sum(d[index])
cat(sprintf(" error%d: %.4f\n",i,error));
alpha=(1/2)*log((1-error)/error);
1-error
log(1)
cat(sprintf("ALPHA%d: %.4f\n",i,alpha));
e<-exp(-alpha*y_h)
cat("e:\t")
cat(sprintf("%.4f\t",e))
cat("\n")
d_e<-d*e
z<-sum(d_e)
cat(sprintf("d%de:\t",i))
cat(sprintf("%.4f\t",d_e))
d<-d_e/z
cat(sprintf(" Z%d: %.4f\n",i,z));
for (i in 1:t){
y_h<-rep(1,n)
index <- miss_index[[i]]
cat(sprintf("d%d:\t",i))
cat(sprintf("%.4f\t",d))
y_h[index]=-1
error <- sum(d[index])
cat(sprintf(" error%d: %.4f\n",i,error));
alpha=(1/2)*log((1-error)/error);
cat(sprintf("ALPHA%d: %.4f\n",i,alpha));
e<-exp(-alpha*y_h)
cat("e:\t")
cat(sprintf("%.4f\t",e))
cat("\n")
d_e<-d*e
z<-sum(d_e)
cat(sprintf("d%de:\t",i))
cat(sprintf("%.4f\t",d_e))
d<-d_e/z
cat(sprintf(" Z%d: %.4f\n",i,z));
}
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Examen/Ejercicio2.R')
#b)
X1<-c(20,30,25,34,31,70,80,74,87,87)
X2<-c(77,73,63,30,20,76,70,51,37,15)
Y<-c(1,-1,1,-1,1,-1,1,-1,1,-1)
Data<- data.frame(X1,X2,Y)
View(Data)
library(adabag);
formulae<-as.factor(Y)~.
adaboost <- boosting(formulae, data=Data, boos=TRUE, mfinal=10,coeflearn='Breiman')
formulae<-Y~.
adaboost <- boosting(formulae, data=Data, boos=TRUE, mfinal=10,coeflearn='Breiman')
adaboost <- boosting(formulae, data=Data)
adaboost <- boosting(Survived~PassengerId+Pclass+Sex+Age+SibSp+Ticket+Fare+Cabin+Embarked, data=dtrain, boos=TRUE, mfinal=5,coeflearn='Breiman')
adaboost <- boosting(formulae, data=Data, boos=TRUE, mfinal=5,coeflearn='Breiman')
adaboost <- boosting(formulae, data=Data, boos=TRUE, mfinal=2,coeflearn='Breiman')
formulae<-as.factor(Y)~.
adaboost <- boosting(formulae, data=Data, boos=TRUE, mfinal=2,coeflearn='Breiman')
Data$Y <- factor(Data$Y)
adaboost <- boosting(Y~X1+X2, data=Data, boos=TRUE, mfinal=2,coeflearn='Breiman')
adaboost <- boosting(Y~X1+X2, data=Data, boos=TRUE, mfinal=5,coeflearn='Breiman')
adaboost <- boosting(Y~X1+X2, data=Data, boos=F, mfinal=5,coeflearn='Breiman')
names(Data)
#b)
rm(list = ls())
X1<-c(20,30,25,34,31,70,80,74,87,87)
X2<-c(77,73,63,30,20,76,70,51,37,15)
Y<-c(1,-1,1,-1,1,-1,1,-1,1,-1)
Data<- data.frame(X1,X2,Y)
Data$Y <- factor(Data$Y)
library(adabag);
adaboost <- boosting(Y~X1+X2, data=Data, boos=F, mfinal=5,coeflearn='Breiman')
adaboost <- boosting(Y~X1+X2, data=Data, boos=T, mfinal=5,coeflearn='Breiman')
x1=rnorm(1000)
x2=rnorm(1000)
y=2*x1+.7*x2+rnorm(1000)
df=data.frame(y,x1,x2,x3=rnorm(1000),x4=rnorm(1000),x5=rnorm(1000))
library(randomForest)
rf1 <- randomForest(y~., data=df, mtry=2,ntree=50,importance=TRUE)
importance(rf1,type=1)
x1=rnorm(1000)
x2=rnorm(1000)
y=rnorm(1000)
df=data.frame(y,x1,x2,x3=rnorm(1000),x4=rnorm(1000),x5=rnorm(1000))
library(randomForest)
rf1 <- randomForest(y~., data=df, mtry=2,ntree=50,importance=TRUE)
importance(rf1,type=1)
x1=rnorm(1000)
x2=rnorm(1000)
y=rnorm(1000)
df=data.frame(y,x1,x2,x3=rnorm(1000),x4=rnorm(1000),x5=rnorm(1000))
library(randomForest)
rf1 <- randomForest(y~., data=df, mtry=2,ntree=50,importance=TRUE)
importance(rf1,type=1)
x1=rnorm(1000)
x2=rnorm(1000)
y=2*x1+.7*x2+rnorm(1000)
df=data.frame(y,x1,x2,x3=rnorm(1000),x4=rnorm(1000),x5=rnorm(1000))
library(randomForest)
rf1 <- randomForest(y~., data=df, mtry=2,ntree=50,importance=TRUE)
importance(rf1,type=1)
#a)-----------------------------------------
rm(list = ls())
library(randomForest)
Data<- read.csv("detect-malicious-URL.csv")
Data$X<-NULL
size <- length(Data[[1]])
ind <- sample(size, size)
accuracyRF<-vector()
k <- 10
for(i in 1:k){
ii <- floor(size/k)*(i-1)+1
is <- floor(size/k)*i
idt <- ind[ii : is]
dtrain <- Data[-idt,]
dtest <- Data[idt,]
RandForest<-randomForest(label~.,dtrain, ntree=100,importance=T)
predRF <- predict(RandForest, dtest)
confusionMatrixRF<-table(predRF, dtest$label)
accuracyRF[i]<-sum(diag(confusionMatrixRF))/sum(confusionMatrixRF)
}
cat("Media del acurracy: ",mean (accuracyRF),"\n")
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Examen/Ejercicio1.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Examen/Ejercicio1.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Examen/Ejercicio1.R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3/Examen/Ejercicio1.R')
levels(Data$url)
View(Data)
library(rpart)
library(nnet)
library(e1071)
ind <- sample(150,150)
idt <- ind[1:10]
dtrain <- Data[-idt,]
dtest <- Data[idt,]
dtestM<-dtest
perceptron<-nnet(label~., dtrain, size=3)
arbol<-rpart(label~., dtrain)
pper<-predict(perceptron,dtest,type="class")
par<-predict(arbol,dtest,type="class")
pper
par
ind <- sample(size,size)
idt <- ind[1:10]
dtrain <- Data[-idt,]
dtest <- Data[idt,]
dtestM<-dtest
perceptron<-nnet(label~., dtrain, size=3)
arbol<-rpart(label~., dtrain)
pper<-predict(perceptron,dtest,type="class")
par<-predict(arbol,dtest,type="class")
pper
par
dtestM$label<-NULL
dtestM <- rbind(dtestM,dtestM)
dtestM<-data.frame(dtestM,label=c(as.character(par) ,pper) )
dtestM
fitSVM<-svm(label~., dtestM )
prediccionGlobal<-predict(fitSVM,dtest,type="class")
matrizconfusion<-table(prediccionGlobal, dtest$label)
matrizconfusion
accuracy<-sum (diag(matrizconfusion))/sum (matrizconfusion)
accuracy
svmRadial<-svm(label~., dtrain)
dtestM<-dtest
perceptron<-nnet(label~., dtrain, size=3)
svmRadial<-svm(label~., dtrain)
pper<-predict(perceptron,dtest,type="class")
par<-predict(svmRadial,dtest,type="class")
pper
par
dtestM$label<-NULL
dtestM <- rbind(dtestM,dtestM)
dtestM<-data.frame(dtestM,label=c(as.character(par) ,pper) )
dtestM
fitSVM<-svm(label~., dtestM )
prediccionGlobal<-predict(fitSVM,dtest,type="class")
matrizconfusion<-table(prediccionGlobal, dtest$label)
matrizconfusion
accuracy<-sum (diag(matrizconfusion))/sum (matrizconfusion)
accuracy
dtestM<-dtest
svmRadial<-svm(label~., dtrain)
arbol<-rpart(label~., dtrain)
pper<-predict(svmRadial,dtest,type="class")
par<-predict(arbol,dtest,type="class")
pper
par
dtestM$label<-NULL
dtestM <- rbind(dtestM,dtestM)
dtestM<-data.frame(dtestM,label=c(as.character(par) ,pper) )
dtestM
fitSVM<-svm(label~., dtestM )
prediccionGlobal<-predict(fitSVM,dtest,type="class")
matrizconfusion<-table(prediccionGlobal, dtest$label)
dtestM<-data.frame(dtestM,label=c(par ,pper) )
dtestM
dtestM<-dtest
svmRadial<-svm(label~., dtrain)
arbol<-rpart(label~., dtrain)
pper<-predict(svmRadial,dtest,type="class")
par<-predict(arbol,dtest,type="class")
pper
par
dtestM$label<-NULL
dtestM <- rbind(dtestM,dtestM)
dtestM<-data.frame(dtestM,label=c(par ,pper) )
dtestM
fitSVM<-svm(label~., dtestM )
prediccionGlobal<-predict(fitSVM,dtest,type="class")
matrizconfusion<-table(prediccionGlobal, dtest$label)
matrizconfusion
accuracy<-sum (diag(matrizconfusion))/sum (matrizconfusion)
accuracy
perceptron<-nnet(label~., dtrain, size=15)
arbol<-rpart(label~., dtrain)
pper<-predict(perceptron,dtest,type="class")
par<-predict(arbol,dtest,type="class")
pper
par
perceptron<-nnet(label~., dtrain, size=49)
perceptron<-nnet(label~., dtrain, size=20)
perceptron<-nnet(label~., dtrain, size=15)
arbol<-rpart(label~., dtrain)
pper<-predict(perceptron,dtest,type="class")
par<-predict(arbol,dtest,type="class")
pper
par
perceptron<-nnet(label~., dtrain, size=15,maxit=100)
arbol<-rpart(label~., dtrain)
pper<-predict(perceptron,dtest,type="class")
par<-predict(arbol,dtest,type="class")
pper
par
dtestM$label<-NULL
dtestM <- rbind(dtestM,dtestM)
dtestM<-data.frame(dtestM,label=c(as.character(par) ,pper) )
dtestM
fitSVM<-svm(label~., dtestM )
prediccionGlobal<-predict(fitSVM,dtest,type="class")
dtestM<-dtest
perceptron<-nnet(label~., dtrain, size=15,maxit=100)
arbol<-rpart(label~., dtrain)
pper<-predict(perceptron,dtest,type="class")
par<-predict(arbol,dtest,type="class")
pper
par
dtestM$label<-NULL
dtestM <- rbind(dtestM,dtestM)
dtestM<-data.frame(dtestM,label=c(as.character(par) ,pper) )
dtestM
fitSVM<-svm(label~., dtestM )
prediccionGlobal<-predict(fitSVM,dtest,type="class")
matrizconfusion<-table(prediccionGlobal, dtest$label)
matrizconfusion
accuracy<-sum (diag(matrizconfusion))/sum (matrizconfusion)
accuracy
SVMradial<-svm(label~.,dtrain)
svmpred<-predict(SVMradial,dtest,type="class")
svmpred
dtestM <- rbind(dtestM,dtestM,dtestM)
dtestM<-data.frame(dtestM,label=c(as.character(par) ,pper,svmpred) )
dtestM
dtestM<-dtest
dtestM$label<-NULL
dtestM <- rbind(dtestM,dtestM,dtestM)
dtestM<-data.frame(dtestM,label=c(as.character(par) ,pper,svmpred) )
dtestM
fitSVM<-svm(label~., dtestM )
prediccionGlobal<-predict(fitSVM,dtest,type="class")
matrizconfusion<-table(prediccionGlobal, dtest$label)
matrizconfusion
dtestM$label<-NULL
dtestM<-data.frame(dtestM,label=c(as.character(par) ,pper,as.character(svmpred) ))
dtestM
fitSVM<-svm(label~., dtestM )
prediccionGlobal<-predict(fitSVM,dtest,type="class")
matrizconfusion<-table(prediccionGlobal, dtest$label)
matrizconfusion
accuracy<-sum (diag(matrizconfusion))/sum (matrizconfusion)
accuracy
adaboost <- boosting(Y~X1+X2, data=Data, boos=T, mfinal=5,coeflearn='Breiman')
#b)
rm(list = ls())
X1<-c(20,30,25,34,31,70,80,74,87,87)
X2<-c(77,73,63,30,20,76,70,51,37,15)
Y<-c(1,-1,1,-1,1,-1,1,-1,1,-1)
Data<- data.frame(X1,X2,Y)
library(adabag);
adaboost <- boosting(Y~X1+X2, data=Data, boos=T, mfinal=5,coeflearn='Breiman')
