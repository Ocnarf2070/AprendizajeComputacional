#Vector de pesos normal al hiperplano
text<-sprintf("Vector de pesos normal al hiperplano (W): (%s)\n",paste(w, collapse=", "))
cat(text)
# Termino independiente
text<-sprintf("Termino independiente (B): %.2f\n",w0)
cat(text)
#Ecuaciones de hiperplano
text<-sprintf("Hiperplanos:\n%.5fx+%.5fy+%.2f=0\n",w[1],w[2],-w0)
cat(text)
text<-sprintf("%.5fx+%.5fy+%.2f=-1\n",w[1],w[2],-w0)
cat(text)
text<-sprintf("%.5fx+%.5fy+%.2f=1\n",w[1],w[2],-w0)
cat(text)
lim<-x+c(-2,2)
plot(x, pch = pchn, bg = colores,xlim = c(min(lim[,1]), max(lim[,1])), ylim =c(min(lim[,2]), max(lim[,2])) )
abline(w0/w[2], -w[1]/w[2])
abline((w0 - 1) / w[2], -w[1] / w[2], lty = 2)
abline((w0 + 1) / w[2], -w[1] / w[2], lty = 2)
#Puntos
c1<-c(4)
c2<-c(5)
Test5<-data.frame(c1,c2)
names(Test5)<-c("x1","x2");
#Prediccion de los puntos
cat("Predicción de puntos:\n")
pred<-predict(svm.prog,Test5)
text<-sprintf("(%s) => %s\n",paste(Test2[1,], collapse=", "),pred[1])
cat(text)
readline(prompt="Press [enter] to continue")
#c)--------------------------------------------------
x1<-c(2,2,-2,-2,2,2,-2,-2,1,1,-1,-1)
x2<-c(2,-2,-2,2,2,-2,-2,2,1,-1,-1,1)
y<-c(1,1,1,1,1,1,1,1,-1,-1,-1,-1)
Data3<-data.frame(x1,x2,y)
c1<-c(5,1)
c2<-c(6,-4)
Test2<-data.frame(c1,c2)
x<-cbind(Data3$x1, Data3$x2)
y <- Data3$y
n0 <- sum(y=='1')
n1 <- sum(y=='-1')
colores <- c(rep("green",n0), rep("red",n1))
pchn <- 21
# Diagrama de dispersion
plot(x, pch = pchn, bg = colores)
#Formula, SVM y datos importantes
formula<-as.factor(y)~.
#Como no es lineal, utilizaremos otro kernel
svm.prog <- svm (formula, data=Data3,kernel = "polynomal", cost = 1000, scale = FALSE)
#Formula, SVM y datos importantes
formula<-y~.
#Como no es lineal, utilizaremos otro kernel
svm.prog <- svm (formula, data=Data3,kernel = "polynomal", cost = 1000, scale = FALSE)
#Como no es lineal, utilizaremos otro kernel
svm.prog <- svm (formula, data=Data3,kernel = "polynomial", cost = 1000, scale = FALSE)
#c)--------------------------------------------------
x1<-c(2,2,-2,-2,2,2,-2,-2,1,1,-1,-1)
x2<-c(2,-2,-2,2,2,-2,-2,2,1,-1,-1,1)
y<-c(1,1,1,1,1,1,1,1,-1,-1,-1,-1)
Data3<-data.frame(x1,x2,y)
x<-cbind(Data3$x1, Data3$x2)
y <- Data3$y
n0 <- sum(y=='1')
n1 <- sum(y=='-1')
colores <- c(rep("green",n0), rep("red",n1))
pchn <- 21
# Diagrama de dispersion
plot(x, pch = pchn, bg = colores)
#Formula, SVM y datos importantes
formula<-as.factor(y)~.
#Como no es lineal, utilizaremos otro kernel
svm.pol <- svm (formula, data=Data3,kernel = "polynomial", cost = 1000, scale = FALSE)
x.svm <-x [svm.pol$index,]
w <- crossprod(x.svm, svm.pol$coefs)
w0 <- svm.pol$rho
#Ancho de banda
text<-sprintf("Ancho de banda: %.5f\n",2/norm(w,type = '2'))
cat(text)
#Vector de pesos normal al hiperplano
text<-sprintf("Vector de pesos normal al hiperplano (W): (%s)\n",paste(w, collapse=", "))
cat(text)
# Termino independiente
text<-sprintf("Termino independiente (B): %.2f\n",w0)
cat(text)
View(svm.pol)
plot(svm.pol,Data3)
#Como no es lineal, utilizaremos otro kernel
svm.pol <- svm (formula, data=Data3,kernel = "radial", cost = 1000, scale = FALSE)
plot(svm.pol,Data3)
x.svm <-x [svm.pol$index,]
w <- crossprod(x.svm, svm.pol$coefs)
w0 <- svm.pol$rho
#Ancho de banda
text<-sprintf("Ancho de banda: %.5f\n",2/norm(w,type = '2'))
cat(text)
#Vector de pesos normal al hiperplano
text<-sprintf("Vector de pesos normal al hiperplano (W): (%s)\n",paste(w, collapse=", "))
cat(text)
svm.pol$coefs
x.svm
crossprod(x.svm, svm.pol$coefs)
drop(t(svm.pol$coefs)%*%x[svm.pol$index,])
drop(t(svm.pol$coefs)*x[svm.pol$index,])
crossprod(x.svm[1:2,1:2], svm.pol$coefs[1:2,[1:2]])
crossprod(x.svm[1:2,1:2], svm.pol$coefs[1:2],[1:2]])
crossprod(x.svm[1:2,1:2], svm.pol$coefs[1:2,1:2]])
crossprod(x.svm[1:2,1:2], svm.pol$coefs[1:2,1:2])
svm.pol$coefs[1:2,1:2]
svm.pol$coefs
crossprod(x.svm[1:2,1:2], svm.pol$coefs[1:2])
plot(svm.pol,Data3)
transform(Data3,x1=4-x2+abs(x1-x2),x2=4-x1+abs(x1-x2),sqrt(x1^2+x2^2)>2)
transform(Data3,x1=4-x2+abs(x1-x2),x2=4-x1+abs(x1-x2),new=sqrt(x1^2+x2^2)>2)
transform(Data3,if(sqrt(x1^2+x2^2)>2){x1=4-x2+abs(x1-x2)},if(sqrt(x1^2+x2^2)>2){x2=4-x1+abs(x1-x2)})
View(Data3)
sqrt(Data$x1^2+Data$x2^2)>2
sqrt(Data3$x1^2+Data3$x2^2)>2
transform(Data3,if(Data3$x1^2+Data3$x2^2)>2){x1=4-x2+abs(x1-x2)},if(Data3$x1^2+Data3$x2^2){x2=4-x1+abs(x1-x2)})
transform(Data3,if(sqrt(x1^2+x2^2)>2){x1=4-x2+abs(x1-x2)},if(sqrt(x1^2+x2^2)>2){x2=4-x1+abs(x1-x2)})
if(sqrt(Data3$x1^2+Data3$x2^2)>2){x2=4-x1+abs(Data$x1-Data$x2)})
if(sqrt(Data3$x1^2+Data3$x2^2)>2){x2=4-x1+abs(Data$x1-Data$x2)}
if(sqrt(Data3$x1^2+Data3$x2^2)>2){x2=4-x1+abs(Data3$x1-Data3$x2)}
x2<-c(2,-2,-2,2,2,-2,-2,2,1,-1,-1,1)
if(sqrt(x1^2+x2^2)>2){x2_2=4-x1+abs(x1-x2)}
x2_2
if(sqrt(Data3$x1^2+Data3$x2^2)>2){x2_2=4-x1+abs(Data3$x1-Data3$x2)}
x2_2
for(i=1:nrow(Data3)){
if(sqrt(Data3$x1[i,1]^2+Data3$x2[i,2]^2)>2){
cat("YES")
}
}
for(i=1:nrow(Data3)){
x1[i,1]
x2[i,2]
if(sqrt(Data3$x1[i,1]^2+Data3$x2[i,2]^2)>2){
cat("YES")
}
}
for(i in 1:nrow(Data3)){
x1[i,1]
x2[i,2]
if(sqrt(Data3$x1[i,1]^2+Data3$x2[i,2]^2)>2){
cat("YES")
}
}
for(i in 1:nrow(Data3)){
Data3$x1[i,1]
Data3$x2[i,2]
if(sqrt(Data3$x1[i,1]^2+Data3$x2[i,2]^2)>2){
cat("YES")
}
}
for(i in 1:nrow(Data3)){
Data3$x1[i]
Data3$x2[i]
if(sqrt(Data3$x1[i,1]^2+Data3$x2[i,2]^2)>2){
cat("YES")
}
}
for(i in 1:nrow(Data3)){
Data3$x1[i]
Data3$x2[i]
if(sqrt(Data3$x1[i]^2+Data3$x2[i]^2)>2){
cat("YES")
}
}
for(i in 1:nrow(Data3)){
Data3$x1[i]
Data3$x2[i]
if(sqrt(Data3$x1[i]^2+Data3$x2[i]^2)>2){
cat("YES\n")
}
}
for(i in 1:nrow(Data3)){
show(Data3$x1[i])
show(Data3$x2[i])
if(sqrt(Data3$x1[i]^2+Data3$x2[i]^2)>2){
cat("YES\n")
}
}
plot(svm.pol,Data3,xlim = c(min(lim[,1]), max(lim[,1])), ylim =c(min(lim[,2]), max(lim[,2])) )
lim<-x+c(-2,2)
plot(svm.pol,Data3,xlim = c(min(lim[,1]), max(lim[,1])), ylim =c(min(lim[,2]), max(lim[,2])) )
#d)--------------------------------------------------
#Transformation
x1<-c(2,2,-2,-2,2,2,-2,-2,1,1,-1,-1)
x2<-c(2,-2,-2,2,2,-2,-2,2,1,-1,-1,1)
y<-c(1,1,1,1,1,1,1,1,-1,-1,-1,-1)
for(i in 1:nrow(x1)){
if(sqrt(x1[i]^2+x2[i]^2)>2){
x1[i]<-4-x2+abs(x1-x2)
x2[i]<-4-x1+abs(x1-x2)
}
}
length(x1)
for(i in 1:length(x1)){
if(sqrt(x1[i]^2+x2[i]^2)>2){
x1[i]<-4-x2+abs(x1-x2)
x2[i]<-4-x1+abs(x1-x2)
}
}
#d)--------------------------------------------------
#Transformation
x1<-c(2,2,-2,-2,2,2,-2,-2,1,1,-1,-1)
x2<-c(2,-2,-2,2,2,-2,-2,2,1,-1,-1,1)
y<-c(1,1,1,1,1,1,1,1,-1,-1,-1,-1)
for(i in 1:length(x1)){
if(sqrt(x1[i]^2+x2[i]^2)>2){
x1[i]<-4-x2+abs(x1-x2)
x2[i]<-4-x1+abs(x1-x2)
}
}
rm(list = ls())
#d)--------------------------------------------------
#Transformation
x1<-c(2,2,-2,-2,2,2,-2,-2,1,1,-1,-1)
x2<-c(2,-2,-2,2,2,-2,-2,2,1,-1,-1,1)
y<-c(1,1,1,1,1,1,1,1,-1,-1,-1,-1)
for(i in 1:length(x1)){
if(sqrt(x1[i]^2+x2[i]^2)>2){
x1[i]<-4-x2+abs(x1-x2)
x2[i]<-4-x1+abs(x1-x2)
}
}
debugSource('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 2/SMV/SVM(1).R')
sqrt(x1[i]^2+x2[i]^2)>2
for(i in 1:length(x1)){
if(sqrt(x1[i]^2+x2[i]^2)>2){
x1[i]<-4-x2[i]+abs(x1[i]-x2[i])
x2[i]<-4-x1[i]+abs(x1[i]-x2[i])
}
}
x1
x2
Data4<-data.frame(x1,x2,y)
x<-cbind(Data4$x1, Data4$x2)
y <- Data4$y
n0 <- sum(y=='1')
n1 <- sum(y=='-1')
colores <- c(rep("green",n0), rep("red",n1))
pchn <- 21
# Diagrama de dispersion
plot(x, pch = pchn, bg = colores)
#Formula, SVM y datos importantes
formula<-as.factor(y)~.
svm.lineal3 <- svm (formula, data=Data4,kernel = "linear", cost = 1000, scale = FALSE)
x.svm <-x [svm.lineal3$index,]
w <- crossprod(x.svm, svm.pol$coefs)
svm.pol$coefs
w <- crossprod(x.svm, svm.lineal3$coefs)
w0 <- svm.lineal3$rho
#Vectores Soporte
summary(svm.lineal3)
#Valores del kernel
A<-x[svm.lineal3$index[1],]
B<-x[svm.lineal3$index[2],]
text<-sprintf("K(A,A)=%.2f\n",crossprod(A,A))
cat(text)
text<-sprintf("K(A,B)=%.2f\n",crossprod(A,B))
cat(text)
text<-sprintf("K(B,A)=%.2f\n",crossprod(B,A))
cat(text)
text<-sprintf("K(B,B)=%.2f\n",crossprod(B,B))
cat(text)
#Ancho de banda
text<-sprintf("Ancho de banda: %.5f\n",2/norm(w,type = '2'))
cat(text)
#Vector de pesos normal al hiperplano
text<-sprintf("Vector de pesos normal al hiperplano (W): (%s)\n",paste(w, collapse=", "))
cat(text)
# Termino independiente
text<-sprintf("Termino independiente (B): %.2f\n",w0)
cat(text)
#Ecuaciones de hiperplano
text<-sprintf("Hiperplanos:\n%.5fx+%.5fy+%.2f=0\n",w[1],w[2],-w0)
cat(text)
text<-sprintf("%.5fx+%.5fy+%.2f=-1\n",w[1],w[2],-w0)
cat(text)
text<-sprintf("%.5fx+%.5fy+%.2f=1\n",w[1],w[2],-w0)
cat(text)
lim<-x+c(-2,2)
plot(x, pch = pchn, bg = colores,xlim = c(min(lim[,1]), max(lim[,1])), ylim =c(min(lim[,2]), max(lim[,2])) )
abline(w0/w[2], -w[1]/w[2])
abline((w0 - 1) / w[2], -w[1] / w[2], lty = 2)
abline((w0 + 1) / w[2], -w[1] / w[2], lty = 2)
readline(prompt="Press [enter] to continue")
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 2/SMV/SVM(1).R')
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 2/SMV/SVM(1).R')
#Vectores Soporte
view(summary(svm.lineal4))
#Vectores Soporte
show(summary(svm.lineal4))
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 2/SMV/SVM(1).R')
show(summary(svm.pol))
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 2/SMV/SVM(1).R')
ççççççççççççççççççççççççççççççççççççççççççççççççççççççççççççççççççç
rm(list = ls())
library(MASS)
library(e1071)
#a)--------------------------------------------------
x1<-c(0,4)
x2<-c(0,4)
y<-c(1,-1)
Data1<-data.frame(x1,x2,y)
x<-cbind(Data1$x1, Data1$x2)
y <- Data1$y
n0 <- sum(y=='1')
n1 <- sum(y=='-1')
colores <- c(rep("green",n0), rep("red",n1))
pchn <- 21
source('D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 2/SMV/SVM(1).R')
setwd("D:/Users/franc/Google Drive/Ingenieria de Informatica/Curso2018-19/Aprendizaje Computacional/Tema 3")
rm(list = ls())
library(rpart)
datos<- read.csv("datos_icb.txt", sep="")
# Generamos Ã¡rboles sobre el dataset
inicio = 0.6
limite = 0.95
pasos = 6
incremento = (limite - inicio)/pasos
tamTrain=0.8
clasificadores = vector();
for(i in 0:5){
set.seed(15*i);
ind<- sample(500,500)
idt <- ind[1:25]
idt
dtrain <- datos[-idt,]
dtest <- datos[idt,]
clasificadores[i] <- rpart(recid ~., data = dtrain, control = rpart.control(minsplit = 10))
}
for(i in 0:5){
set.seed(15*i);
ind<- sample(500,500)
idt <- ind[1:25]
cat(idt)
dtrain <- datos[-idt,]
dtest <- datos[idt,]
clasificadores[i] <- rpart(recid ~., data = dtrain, control = rpart.control(minsplit = 10))
}
for(i in 0:5){
set.seed(15*i);
ind<- sample(500,500)
idt <- ind[1:25]
cat(idt)
cat("\n")
dtrain <- datos[-idt,]
dtest <- datos[idt,]
clasificadores[i] <- rpart(recid ~., data = dtrain, control = rpart.control(minsplit = 10))
}
set.seed(Sys.Date());
# Elegimos una instancia al azar
instancia <- datos[sample(nrow(datos), 1), ]
clasificadores[[i]]
clasificadores[[1]]
clasificadores[[2]]
clasificadores[[7]]
clasificadores[[6]]
clasificadores[[5]]
# Predecimos con cada clasificador
predicciones = vector();
for(i in 1:pasos-1){
predicciones [[i]] <- predict(clasificadores[[i]],instancia,type="prob")
}
View(clasificadores)
clasificadores[1]
clasificadores[]
View(clasificadores)
View(clasificadores[[1]])
m<-rpart(recid ~., data = dtrain, control = rpart.control(minsplit = 10))
}
m<-rpart(recid ~., data = dtrain, control = rpart.control(minsplit = 10))
View(m)
View(as.list(clasificadores[[1]]))
for(i in 0:5){
set.seed(15*i);
ind<- sample(500,500)
idt <- ind[1:25]
cat(idt)
cat("\n")
dtrain <- datos[-idt,]
dtest <- datos[idt,]
clas<-
clasificadores[[i]] <- rpart(recid ~., data = dtrain, control = rpart.control(minsplit = 10))
}
clasificadores = list();
for(i in 0:5){
set.seed(15*i);
ind<- sample(500,500)
idt <- ind[1:25]
cat(idt)
cat("\n")
dtrain <- datos[-idt,]
dtest <- datos[idt,]
clas<-
clasificadores[[i]] <- rpart(recid ~., data = dtrain, control = rpart.control(minsplit = 10))
}
for(i in 0:5){
set.seed(15*i);
ind<- sample(500,500)
idt <- ind[1:25]
cat(idt)
cat("\n")
dtrain <- datos[-idt,]
dtest <- datos[idt,]
clas<-
clasificadores[[i]] <- rpart(recid ~., data = dtrain)
}
clasificadores = list();
for(i in 0:5){
set.seed(15*i);
ind<- sample(500,500)
idt <- ind[1:25]
cat(idt)
cat("\n")
dtrain <- datos[-idt,]
dtest <- datos[idt,]
clasificadores[[i]] = rpart(recid ~., data = dtrain)
}
n = 500
> set.seed(1)
> X = rnorm(n)
> ma = 10-(X+1.5)^2*2
> mb = -10+(X-1.5)^2*2
> M = cbind(ma,mb)
> set.seed(1)
> Z = sample(1:2,size=n,replace=TRUE)
> Y = ma*(Z==1)+mb*(Z==2)+rnorm(n)*5
> df = data.frame(Z=as.factor(Z),X,Y)
n = 500
set.seed(1)
X = rnorm(n)
ma = 10-(X+1.5)^2*2
mb = -10+(X-1.5)^2*2
M = cbind(ma,mb)
set.seed(1)
Z = sample(1:2,size=n,replace=TRUE)
Y = ma*(Z==1)+mb*(Z==2)+rnorm(n)*5
df = data.frame(Z=as.factor(Z),X,Y)
FIT=list()
> for(i in 1:n)
FIT[[i]] = randomForest(Z~X+Y,data=df[-i,])
predict_i = function(i)
predict(FIT[[i]],newdata=df[i,],
+ type="prob")[,2]
S = Vectorize(predict_i)(1:n)
FIT=list()
> for(i in 1:n)
FIT[[i]] = randomForest(Z~X+Y,data=df[-i,])
predict_i = function(i)
predict(FIT[[i]],newdata=df[i,], type="prob")[,2]
S = Vectorize(predict_i)(1:n)
FIT=list()
for(i in 1:n) {
FIT[[i]] = randomForest(Z~X+Y,data=df[-i,])
predict_i = function(i)
predict(FIT[[i]],newdata=df[i,],type="prob")[,2]
S = Vectorize(predict_i)(1:n)
}
library(randomForest)
for(i in 1:n) {
FIT[[i]] = randomForest(Z~X+Y,data=df[-i,])
predict_i = function(i)
predict(FIT[[i]],newdata=df[i,],type="prob")[,2]
S = Vectorize(predict_i)(1:n)
}
FIT[[i]] = randomForest(Z~X+Y,data=df[-i,])
predict_i = function(i)
predict(FIT[[i]],newdata=df[i,],type="prob")[,2]
S = Vectorize(predict_i)(1:n)
for(i in 1:n) {
FIT[[i]] = randomForest(Z~X+Y,data=df[-i,])
predict_i = function(i)
predict(FIT[[i]],newdata=df[i,],type="prob")[,2]
S = Vectorize(predict_i)(1:n)
}
FIT[[i]] = randomForest(Z~X+Y,data=df[-i,])
predict_i = function(i)
predict(FIT[[i]],newdata=df[i,],type="prob")[,2]
S = Vectorize(predict_i)(1:n)
for(i in 1:n) {
FIT[[i]] = randomForest(Z~X+Y,data=df[-i,])
predict_i = function(i)
predict(FIT[[i]],newdata=df[i,],type="prob")[,2]
}
S = Vectorize(predict_i)(1:n)
s
S
predict_i()
predict_i(1:n)
library(randomForest)
for(i in 1:n) {
FIT[[i]] = randomForest(Z~X+Y,data=df[-i,])
}
predict_i = function(i){
predict(FIT[[i]],newdata=df[i,],type="prob")[,2]
}
S = Vectorize(predict_i)(1:n)
View(FIT)
n=10
for(i in 1:n) {
FIT[[i]] = rpart(Z~X+Y,data=df[-i,])
}
FIT=list()
library(randomForest)
for(i in 1:n) {
FIT[[i]] = rpart(Z~X+Y,data=df[-i,])
}
View(FIT)
View(FIT)
S = Vectorize(predict_i)(1:n)
